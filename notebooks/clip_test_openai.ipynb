{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fd90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install clip doesn't work, so we need to install from the repo\n",
    "# pip install git+https://github.com/openai/CLIP.git\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import clip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68658d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(audio_path, save_path=None):\n",
    "    # Load audio\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Create spectrogram\n",
    "    spectrogram = torchaudio.transforms.Spectrogram()(waveform)\n",
    "    \n",
    "    # Convert to image\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(spectrogram[0].log2().numpy(), aspect='auto')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        return save_path\n",
    "    else:\n",
    "        # Convert plot to image\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.close()\n",
    "        return plt\n",
    "\n",
    "def wav_to_jpg_filename(path_with_filename):\n",
    "    base = os.path.basename(path_with_filename)         # \"snare_1.wav\"\n",
    "    name, _ = os.path.splitext(base)                    # (\"snare_1\", \".wav\")\n",
    "    return f\"{name}.jpg\"                                # \"snare_1.jpg\"\n",
    "\n",
    "\n",
    "def get_wav_files_and_labels(root_dir):\n",
    "    \"\"\"\n",
    "    Recursively fetch all .wav files and assign labels based on the parent directory name.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str or Path): Root directory to search for .wav files.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: (filepath, label)\n",
    "    \"\"\"\n",
    "    root = Path(root_dir)\n",
    "    files_with_labels = []\n",
    "\n",
    "    for wav_file in root.rglob('*.wav'):\n",
    "        label = wav_file.parent.name\n",
    "        files_with_labels.append((str(wav_file), label))\n",
    "\n",
    "    return files_with_labels\n",
    "\n",
    "def find_tuple_string(array, target_string):\n",
    "    \"\"\"\n",
    "    Searches for a target string in the first element of tuples in an array.\n",
    "    If found, returns the second element of the tuple.\n",
    "\n",
    "    Args:\n",
    "        array (list): A list of tuples.\n",
    "        target_string (str): The string to search for.\n",
    "\n",
    "    Returns:\n",
    "        any: The second element of the tuple if the string is found, otherwise None.\n",
    "    \"\"\"\n",
    "    for tup in array:\n",
    "        if tup[1] == target_string:\n",
    "            return tup[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_spectogram_files(folder_name):\n",
    "    \"\"\"\n",
    "    Reads all files in a directory and returns them as an array of tuples.\n",
    "    The first part of the tuple is the filename (including the path), \n",
    "    the second part is a label created from the filename.\n",
    "\n",
    "    Args:\n",
    "        folder_name (str): The path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing the filename and label.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for filename in os.listdir(folder_name):\n",
    "        filepath = os.path.join(folder_name, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            label = \"_\".join(filename.split(\"_\")[:-1]).split(\".\")[0]\n",
    "            files.append((filepath, label))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a32d1457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating names for CLIP + mapping categories\n",
    "drum_mapping_categories = [\n",
    "                    (\"snare drum\",      \"snare\"), \n",
    "                    (\"bass drum\",       \"bass\"),\n",
    "                    (\"hi-hat drum\",     \"hihat_closed\"),\n",
    "                    (\"hi-hat drum\",     \"hihat_open\"),\n",
    "                    (\"tom-tom drum\",    \"tomtom_low\"),\n",
    "                    (\"tom-tom drum\",    \"tomtom_mid\"),\n",
    "                    (\"tom-tom drum\",    \"tomtom_hi\"),\n",
    "                    (\"cymbal drum\",     \"cymbal\")\n",
    "                ]\n",
    "\n",
    "drum_categories_for_clip = sorted({item[0] for item in drum_mapping_categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad3657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct --> Have this: tomtom_low (path ../out/clip_test_openai/tomtom_low_3.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_1.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Correct --> Have this: tomtom_hi (path ../out/clip_test_openai/tomtom_hi_2.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: hihat_open (path ../out/clip_test_openai/hihat_open_2.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Error --> Have this: kick (path ../out/clip_test_openai/kick_2.jpg) gets classified as: tom-tom drum (expected None)\n",
      "Error --> Have this: hihat_open (path ../out/clip_test_openai/hihat_open_3.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Correct --> Have this: tomtom_mid (path ../out/clip_test_openai/tomtom_mid_3.jpg) gets classified as: tom-tom drum\n",
      "Correct --> Have this: tomtom_low (path ../out/clip_test_openai/tomtom_low_2.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: snare (path ../out/clip_test_openai/snare_4.jpg) gets classified as: tom-tom drum (expected snare drum)\n",
      "Error --> Have this: cymbal (path ../out/clip_test_openai/cymbal_4.jpg) gets classified as: hi-hat drum (expected cymbal drum)\n",
      "Correct --> Have this: tomtom_low (path ../out/clip_test_openai/tomtom_low_1.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_5.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_6.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_3.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Error --> Have this: cymbal (path ../out/clip_test_openai/cymbal_3.jpg) gets classified as: tom-tom drum (expected cymbal drum)\n",
      "Error --> Have this: kick (path ../out/clip_test_openai/kick_4.jpg) gets classified as: tom-tom drum (expected None)\n",
      "Error --> Have this: snare (path ../out/clip_test_openai/snare_3.jpg) gets classified as: tom-tom drum (expected snare drum)\n",
      "Error --> Have this: kick (path ../out/clip_test_openai/kick_1.jpg) gets classified as: bass drum (expected None)\n",
      "Error --> Have this: snare (path ../out/clip_test_openai/snare_7.jpg) gets classified as: tom-tom drum (expected snare drum)\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_4.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Error --> Have this: snare (path ../out/clip_test_openai/snare_5.jpg) gets classified as: tom-tom drum (expected snare drum)\n",
      "Correct --> Have this: tomtom_hi (path ../out/clip_test_openai/tomtom_hi_3.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: cymbal (path ../out/clip_test_openai/cymbal_1.jpg) gets classified as: tom-tom drum (expected cymbal drum)\n",
      "Correct --> Have this: tomtom_hi (path ../out/clip_test_openai/tomtom_hi_1.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: kick (path ../out/clip_test_openai/kick_5.jpg) gets classified as: tom-tom drum (expected None)\n",
      "Error --> Have this: kick (path ../out/clip_test_openai/kick_3.jpg) gets classified as: tom-tom drum (expected None)\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_7.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Error --> Have this: cymbal (path ../out/clip_test_openai/cymbal_2.jpg) gets classified as: tom-tom drum (expected cymbal drum)\n",
      "Correct --> Have this: tomtom_mid (path ../out/clip_test_openai/tomtom_mid_2.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: snare (path ../out/clip_test_openai/snare_2.jpg) gets classified as: tom-tom drum (expected snare drum)\n",
      "Error --> Have this: snare (path ../out/clip_test_openai/snare_6.jpg) gets classified as: tom-tom drum (expected snare drum)\n",
      "Error --> Have this: hihat_open (path ../out/clip_test_openai/hihat_open_1.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Correct --> Have this: tomtom_mid (path ../out/clip_test_openai/tomtom_mid_1.jpg) gets classified as: tom-tom drum\n",
      "Error --> Have this: snare (path ../out/clip_test_openai/snare_1.jpg) gets classified as: tom-tom drum (expected snare drum)\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_2.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Error --> Have this: hihat_closed (path ../out/clip_test_openai/hihat_closed_8.jpg) gets classified as: tom-tom drum (expected hi-hat drum)\n",
      "Correct: 9, Incorrect: 27\n",
      "../data/pictures/dog/dog_1.png is classified as: a photo of a dog (probs: [9.595e-01 6.241e-05 3.103e-03 3.720e-02])\n",
      "../data/pictures/dog/dog_2.png is classified as: a photo of a dog (probs: [7.056e-01 9.125e-05 3.498e-04 2.942e-01])\n",
      "../data/pictures/dog/dog_3.png is classified as: a photo of a dog (probs: [9.800e-01 1.051e-04 3.426e-03 1.660e-02])\n",
      "../data/pictures/cat/cat_1.png is classified as: a photo of a cat (probs: [1.086e-03 7.451e-01 1.109e-04 2.537e-01])\n",
      "../data/pictures/cat/cat_2.png is classified as: a photo of a cat (probs: [2.857e-03 8.433e-01 4.520e-04 1.536e-01])\n",
      "../data/pictures/cat/cat_3.png is classified as: a photo of a cat (probs: [2.5539e-03 8.8135e-01 2.4915e-04 1.1566e-01])\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"../out/clip_test_openai\", exist_ok=True)\n",
    "\n",
    "\n",
    "# Create spectograms for all drum samples\n",
    "for drum_sample_wav, label in get_wav_files_and_labels('../data/samples/'):\n",
    "    drum_sample_jpg = \"../out/clip_test_openai/\" + wav_to_jpg_filename(drum_sample_wav)\n",
    "    classification = audio_to_spectrogram(drum_sample_wav, drum_sample_jpg)\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "for spectogram_jpg, label in read_spectogram_files('../out/clip_test_openai/'):\n",
    "\n",
    "    # Load spectrogram image\n",
    "    image = preprocess(Image.open(spectogram_jpg)).unsqueeze(0).to(device)\n",
    "\n",
    "    # Correct: 10, Incorrect: 26\n",
    "    texts = [f\"A spectrogram of a {category} sound.\" for category in drum_categories_for_clip]\n",
    "\n",
    "    # Correct: 6, Incorrect: 30\n",
    "    #texts = [f\"a {category}\" for category in drum_categories_for_clip]\n",
    "\n",
    "    # Prepare text inputs\n",
    "    text = clip.tokenize(texts).to(device)\n",
    "\n",
    "    # Get features and compute similarity\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        text_features = model.encode_text(text)\n",
    "        logits_per_image = image_features @ text_features.T\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    classification = drum_categories_for_clip[probs.argmax().item()], probs.tolist()[0]\n",
    "    mapped_value = find_tuple_string(drum_mapping_categories, label)\n",
    "\n",
    "    if mapped_value == classification[0]:\n",
    "        correct += 1\n",
    "        print(f\"Correct --> Have this: {label} (path {spectogram_jpg}) gets classified as: {classification[0]}\")\n",
    "    else:\n",
    "        incorrect += 1\n",
    "        print(f\"Error --> Have this: {label} (path {spectogram_jpg}) gets classified as: {classification[0]} (expected {mapped_value})\")\n",
    "\n",
    "print(f\"Correct: {correct}, Incorrect: {incorrect}\")\n",
    "\n",
    "\n",
    "# Vaildation - How about dogs and cats?\n",
    "dogs_cats = ['../data/pictures/dog/dog_1.png',\n",
    "              '../data/pictures/dog/dog_2.png', \n",
    "              '../data/pictures/dog/dog_3.png', \n",
    "              '../data/pictures/cat/cat_1.png', \n",
    "              '../data/pictures/cat/cat_2.png',\n",
    "              '../data/pictures/cat/cat_3.png']\n",
    "\n",
    "for dog_cat in dogs_cats:\n",
    "    image = Image.open(dog_cat)\n",
    "    texts = [\"a photo of a dog\", \"a photo of a cat\", \"a photo of a cat and dog\", \"a photo of Novia\"]\n",
    "\n",
    "    # Preprocess the image for CLIP\n",
    "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Tokenize the text prompts\n",
    "    text_inputs = clip.tokenize(texts).to(device)\n",
    "\n",
    "    # Get image and text features, compute similarity\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "        logits_per_image = image_features @ text_features.T\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    # Print the most likely label and probabilities\n",
    "    predicted_label = texts[probs.argmax()]\n",
    "    print(f\"{dog_cat} is classified as: {predicted_label} (probs: {probs[0]})\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
